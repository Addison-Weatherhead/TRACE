import torch
import torch.nn as nn
import math
import numpy as np
from torch.utils import data
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import torch.nn.functional as F

class EncoderMultiSignalMIMIC(nn.Module):
    # Encoder from Cardiac Arrest paper
    def __init__(self, latent_size, encoding_size, in_channel, device='cpu'):
        """
        Encoder of patient condition into lower dimensional encoding space, using time series signals.
        First layer convolution extracts features into a latent variable, which feeds into an RNN to
        generate the encoding
        :param latent_size: size of the latent paramteters generated by the CNN
        :param encoding_size: Size of the final encoding
        """
        super(EncoderMultiSignalMIMIC, self).__init__()
        self.latent_size = latent_size
        self.encoding_size = encoding_size
        self.in_channel = in_channel # This will be 2, for data and maps
        out_channel = self.latent_size
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self.conv = nn.Sequential(nn.Conv2d(in_channels=self.in_channel, out_channels=32, padding=0, kernel_size=(3, 1)),
                                  # nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=32),
                                  nn.Conv2d(in_channels=32, out_channels=64, padding=0, kernel_size=(3, 1)),
                                  nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=64),
                                  nn.Conv2d(in_channels=64, out_channels=32, padding=0, kernel_size=(8, 1)), # changed kernel_size from (10,4) to (8,4) so data with 8 features will lead to output dim c = 1 (see comment below)
                                  nn.MaxPool2d(kernel_size=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=32),
                                  nn.Conv2d(in_channels=32, out_channels=self.latent_size, kernel_size=(3, 1)),
                                  nn.ReLU())
        #==





        #==



        
        # Output of the convolutional layers is of shape (a, b, c, d). a=batch size, b=self.latent_size, c=1, d is determined by data dimension, kernel sizes, and stride, but is 
        # essentially representing the time dimension. So as the input we had data of shape (num_features, seq_len), and now our latent states are of shape (latent_size, d), 
        # where latent_size <= num_features, and d <= seq_len (although in most cases these will probably be < not <=)


        # self.conv = nn.Sequential(nn.Conv2d(in_channels=self.in_channel, out_channels=16, padding=0, kernel_size=(1, 4)),
        #                           nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
        #                           nn.ReLU(),
        #                           nn.Dropout(0.5),
        #                           nn.BatchNorm2d(num_features=16),
        #                           nn.Conv2d(in_channels=16, out_channels=32, padding=0, kernel_size=(1, 4)),
        #                           nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
        #                           nn.ReLU(),
        #                           nn.Dropout(0.5),
        #                           nn.BatchNorm2d(num_features=32),
        #                           nn.Conv2d(in_channels=32, out_channels=32, padding=0, kernel_size=(10, 4)),
        #                           nn.MaxPool2d(kernel_size=(1, 2)),
        #                           nn.ReLU(),
        #                           nn.Dropout(0.5),
        #                           nn.BatchNorm2d(num_features=32),
        #                           nn.Conv2d(in_channels=32, out_channels=self.latent_size, kernel_size=(1, 4)),
        #                           nn.ReLU())

        self.att_weights = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(10, 16), stride=(1, 2)),
                                         nn.MaxPool2d(kernel_size=(1, 20), stride=(1, 2)),
                                         nn.ReLU())

        # input is of size latent_size, output is of size 2*self.encoding_size
        self.rnn = nn.GRUCell(self.latent_size, 2 * self.encoding_size) # Want to generate a distribution, so we create mean and variance vectors.
        
        # Parameters of the posterior distribution of the latent representation
        self.mus = torch.nn.Sequential(nn.Linear(2 * self.encoding_size, self.encoding_size))
        self.cov = torch.nn.Sequential(torch.nn.Linear(2 * self.encoding_size, self.encoding_size),
                                       torch.nn.ReLU())

        torch.nn.init.xavier_uniform_(self.mus[0].weight)
        torch.nn.init.xavier_uniform_(self.cov[0].weight)

    def forward(self, x, kl_loss=False, past_state=None):
        # x is of shape (num_samples, 2, num_features, signal_length)
        if len(tuple(x.shape)) == 3: # if a single window is being passed in
            x = x.unsqueeze(0) # Make it a batch size of 1 so its 4 dimensional.
        hiddens = self.get_distribution_params(x, past_state) # Shape: latent_seq_len, batch_size, 2*encoding_size
        
        

        # If we want to use attention weights, uncomment the section below:
        # weights = self.att_weights(x[:,1,:,:].unsqueeze(1))
        # weights = weights.view(weights.shape[0],weights.shape[-1])  # Shape:[batch_size, time_steps]
        # weights = torch.nn.Softmax(-1)(weights)
        # hiddens = torch.sum(hiddens.permute(1,0,2)*weights.unsqueeze(-1) ,1)
        # encoding = self.fc(latent)

        hiddens = hiddens.permute(1,0,2) # shape: [batch_size, latent_seq_len, 2*encoding_size]

        mus = self.mus(hiddens[:, -1, :]) # Take the most recent hidden state from the RNN (i.e. the one that summarizes the sequence)
        std = self.cov(hiddens[:, -1, :]) # mus and std are each of shape (batch_size, 1, encoding_size)
        
        kl_z = 0.5 * (torch.bmm(mus.unsqueeze(1), mus.unsqueeze(-1)) + torch.bmm(std.unsqueeze(1), std.unsqueeze(-1)) - \
                      mus.shape[-1] - torch.sum(torch.log((std+1e-5) ** 2), -1)) # What's going on here?

        if kl_loss:
            return mus + std * torch.randn(std.shape).to(self.device), kl_z

        return mus + std * torch.randn(std.shape).to(self.device) # Doesn't return a distribution, returns a sample of the distribution.

    def forward_weights(self, x, past_state=None):
        hiddens = self.get_distribution_params(x, past_state)  # Shape:[time_steps, batch_size, latent_size]
        weights = self.att_weights(x)
        weights = weights.view(weights.shape[0],weights.shape[-1])  # Shape:[batch_size, time_steps]
        weights = torch.nn.Softmax(-1)(weights)
        encoding = hiddens.permute(1,0,2)*weights.unsqueeze(-1) # shape: [batch, t, f]

        mus = encoding[:, :encoding.shape[-1] // 2]
        std = encoding[:, encoding.shape[-1] // 2:]
        return mus + std*0.01*torch.randn(std.shape).to(self.device), weights

    def forward_all(self, x):
        latent_rep_arr = []
        encodings = self.get_distribution_params(x)
        for encoding in encodings:
            mus = encoding[:, :encoding.shape[-1] // 2]
            std = encoding[:, encoding.shape[-1] // 2:]
            z = mus + std*0.01*torch.randn(std.shape).to(self.device)
            latent_rep_arr.append(z)
        latent_rep = torch.stack(latent_rep_arr)
        return latent_rep

    def get_distribution_params(self, x, past_state=None):
        encodings_arr = []
        x = x.to(self.device)
        '''
        print('INPUT SHAPE TO ENCODER: ', x.shape)
        
        z = self.conv1(x)
        print('z1 shape: ', z.shape)
        z = self.mp1(z)
        z = self.relu1(z)
        z = self.dropout1(z)
        z = self.bn1(z)
        print('z1 shape: ', z.shape)

        
        z = self.conv2(z)
        print('z2 shape: ', z.shape)
        z = self.mp2(z)
        z = self.relu2(z)
        z = self.dropout2(z)
        z = self.bn2(z)
        print('z2 shape: ', z.shape)
        
        z = self.conv3(z)
        print('z3 shape: ', z.shape)
        z = self.mp3(z)
        z = self.relu3(z)
        z = self.dropout3(z)
        z = self.bn3(z)
        print('z3 shape: ', z.shape)
        
        z = self.conv4(z)
        print('z4 shape: ', z.shape)
        z = self.relu4(z)
        
        '''
        
        
        z = self.conv(x) # Latent state of shape (batch_size, latent_size, 1, latent_seq_len), where latent_seq_len is the compressed time dimension
        z = z.squeeze(3) # remove the dimension of size 1
        batch_size, latent_size, latent_seq_len = z.shape
        encodings_arr.append(self.rnn(z[:, :, 0].view(batch_size, self.latent_size), )) # No previous RNN hidden state to pass in so we leave empty
        for i in range(1, latent_seq_len):
            encodings_arr.append(self.rnn(z[:,:,i].view(batch_size,self.latent_size), encodings_arr[-1])) # Grabbing the most recent hidden state each time
        
        # encodings.shape is latent_seq_len, batch_size, 2*encoding_size
        encodings = torch.stack(encodings_arr)
        return encodings

class EncoderMultiSignal(nn.Module):
    # Encoder from Cardiac Arrest paper
    def __init__(self, latent_size, encoding_size, in_channel, device='cpu'):
        """
        Encoder of patient condition into lower dimensional encoding space, using time series signals.
        First layer convolution extracts features into a latent variable, which feeds into an RNN to
        generate the encoding
        :param latent_size: size of the latent paramteters generated by the CNN
        :param encoding_size: Size of the final encoding
        """
        super(EncoderMultiSignal, self).__init__()
        self.latent_size = latent_size
        self.encoding_size = encoding_size
        self.in_channel = in_channel # This will be 2, for data and maps
        out_channel = self.latent_size
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self.conv = nn.Sequential(nn.Conv2d(in_channels=self.in_channel, out_channels=32, padding=0, kernel_size=(1, 3)),
                                  # nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=32),
                                  nn.Conv2d(in_channels=32, out_channels=64, padding=0, kernel_size=(1, 3)),
                                  nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=64),
                                  nn.Conv2d(in_channels=64, out_channels=32, padding=0, kernel_size=(8, 3)), # changed kernel_size from (10,4) to (8,4) so data with 8 features will lead to output dim c = 1 (see comment below)
                                  nn.MaxPool2d(kernel_size=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=32),
                                  nn.Conv2d(in_channels=32, out_channels=self.latent_size, kernel_size=(1, 3)),
                                  nn.ReLU())
        #==


        self.conv1 = nn.Conv2d(in_channels=self.in_channel, out_channels=32, padding=0, kernel_size=(1, 3))
        self.mp1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(0.5)
        self.bn1 = nn.BatchNorm2d(num_features=32)
        
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, padding=0, kernel_size=(1, 3))
        self.mp2 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(0.5)
        self.bn2 = nn.BatchNorm2d(num_features=64)
        
        self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, padding=0, kernel_size=(8, 3)) # changed kernel_size from (10,4) to (8,4) so data with 8 features will lead to output dim c = 1 (see comment below)
        self.mp3 = nn.MaxPool2d(kernel_size=(1, 2))
        self.relu3 = nn.ReLU()
        self.dropout3 = nn.Dropout(0.5)
        self.bn3 = nn.BatchNorm2d(num_features=32)
        
        self.conv4 = nn.Conv2d(in_channels=32, out_channels=self.latent_size, kernel_size=(1, 3))
        self.relu4 = nn.ReLU()



        #==



        
        # Output of the convolutional layers is of shape (a, b, c, d). a=batch size, b=self.latent_size, c=1, d is determined by data dimension, kernel sizes, and stride, but is 
        # essentially representing the time dimension. So as the input we had data of shape (num_features, seq_len), and now our latent states are of shape (latent_size, d), 
        # where latent_size <= num_features, and d <= seq_len (although in most cases these will probably be < not <=)


        # self.conv = nn.Sequential(nn.Conv2d(in_channels=self.in_channel, out_channels=16, padding=0, kernel_size=(1, 4)),
        #                           nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
        #                           nn.ReLU(),
        #                           nn.Dropout(0.5),
        #                           nn.BatchNorm2d(num_features=16),
        #                           nn.Conv2d(in_channels=16, out_channels=32, padding=0, kernel_size=(1, 4)),
        #                           nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
        #                           nn.ReLU(),
        #                           nn.Dropout(0.5),
        #                           nn.BatchNorm2d(num_features=32),
        #                           nn.Conv2d(in_channels=32, out_channels=32, padding=0, kernel_size=(10, 4)),
        #                           nn.MaxPool2d(kernel_size=(1, 2)),
        #                           nn.ReLU(),
        #                           nn.Dropout(0.5),
        #                           nn.BatchNorm2d(num_features=32),
        #                           nn.Conv2d(in_channels=32, out_channels=self.latent_size, kernel_size=(1, 4)),
        #                           nn.ReLU())

        self.att_weights = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(10, 16), stride=(1, 2)),
                                         nn.MaxPool2d(kernel_size=(1, 20), stride=(1, 2)),
                                         nn.ReLU())

        # input is of size latent_size, output is of size 2*self.encoding_size
        self.rnn = nn.GRUCell(self.latent_size, 2 * self.encoding_size) # Want to generate a distribution, so we create mean and variance vectors.
        
        # Parameters of the posterior distribution of the latent representation
        self.mus = torch.nn.Sequential(nn.Linear(2 * self.encoding_size, self.encoding_size))
        self.cov = torch.nn.Sequential(torch.nn.Linear(2 * self.encoding_size, self.encoding_size),
                                       torch.nn.ReLU())

        torch.nn.init.xavier_uniform_(self.mus[0].weight)
        torch.nn.init.xavier_uniform_(self.cov[0].weight)

    def forward(self, x, kl_loss=False, past_state=None):
        # x is of shape (num_samples, 2, num_features, signal_length)
        if len(tuple(x.shape)) == 3: # if a single window is being passed in
            x = x.unsqueeze(0) # Make it a batch size of 1 so its 4 dimensional.
        hiddens = self.get_distribution_params(x, past_state) # Shape: latent_seq_len, batch_size, 2*encoding_size
        
        

        # If we want to use attention weights, uncomment the section below:
        # weights = self.att_weights(x[:,1,:,:].unsqueeze(1))
        # weights = weights.view(weights.shape[0],weights.shape[-1])  # Shape:[batch_size, time_steps]
        # weights = torch.nn.Softmax(-1)(weights)
        # hiddens = torch.sum(hiddens.permute(1,0,2)*weights.unsqueeze(-1) ,1)
        # encoding = self.fc(latent)

        hiddens = hiddens.permute(1,0,2) # shape: [batch_size, latent_seq_len, 2*encoding_size]

        mus = self.mus(hiddens[:, -1, :]) # Take the most recent hidden state from the RNN (i.e. the one that summarizes the sequence)
        std = self.cov(hiddens[:, -1, :]) # mus and std are each of shape (batch_size, 1, encoding_size)
        
        kl_z = 0.5 * (torch.bmm(mus.unsqueeze(1), mus.unsqueeze(-1)) + torch.bmm(std.unsqueeze(1), std.unsqueeze(-1)) - \
                      mus.shape[-1] - torch.sum(torch.log((std+1e-5) ** 2), -1)) # What's going on here?

        if kl_loss:
            return mus + std * torch.randn(std.shape).to(self.device), kl_z

        return mus + std * torch.randn(std.shape).to(self.device) # Doesn't return a distribution, returns a sample of the distribution.

    def forward_weights(self, x, past_state=None):
        hiddens = self.get_distribution_params(x, past_state)  # Shape:[time_steps, batch_size, latent_size]
        weights = self.att_weights(x)
        weights = weights.view(weights.shape[0],weights.shape[-1])  # Shape:[batch_size, time_steps]
        weights = torch.nn.Softmax(-1)(weights)
        encoding = hiddens.permute(1,0,2)*weights.unsqueeze(-1) # shape: [batch, t, f]

        mus = encoding[:, :encoding.shape[-1] // 2]
        std = encoding[:, encoding.shape[-1] // 2:]
        return mus + std*0.01*torch.randn(std.shape).to(self.device), weights

    def forward_all(self, x):
        latent_rep_arr = []
        encodings = self.get_distribution_params(x)
        for encoding in encodings:
            mus = encoding[:, :encoding.shape[-1] // 2]
            std = encoding[:, encoding.shape[-1] // 2:]
            z = mus + std*0.01*torch.randn(std.shape).to(self.device)
            latent_rep_arr.append(z)
        latent_rep = torch.stack(latent_rep_arr)
        return latent_rep

    def get_distribution_params(self, x, past_state=None):
        encodings_arr = []
        x = x.to(self.device)
        '''
        print('INPUT SHAPE TO ENCODER: ', x.shape)
        
        z = self.conv1(x)
        print('z1 shape: ', z.shape)
        z = self.mp1(z)
        z = self.relu1(z)
        z = self.dropout1(z)
        z = self.bn1(z)
        print('z1 shape: ', z.shape)

        
        z = self.conv2(z)
        print('z2 shape: ', z.shape)
        z = self.mp2(z)
        z = self.relu2(z)
        z = self.dropout2(z)
        z = self.bn2(z)
        print('z2 shape: ', z.shape)
        
        z = self.conv3(z)
        print('z3 shape: ', z.shape)
        z = self.mp3(z)
        z = self.relu3(z)
        z = self.dropout3(z)
        z = self.bn3(z)
        print('z3 shape: ', z.shape)
        
        z = self.conv4(z)
        print('z4 shape: ', z.shape)
        z = self.relu4(z)
        
        '''
        
        
        
        
        z = self.conv(x) # Latent state of shape (batch_size, latent_size, 1, latent_seq_len), where latent_seq_len is the compressed time dimension
        z = z.squeeze(2) # remove the dimension of size 1
        batch_size, latent_size, latent_seq_len = z.shape
        encodings_arr.append(self.rnn(z[:, :, 0].view(batch_size, self.latent_size), )) # No previous RNN hidden state to pass in so we leave empty
        for i in range(1, latent_seq_len):
            encodings_arr.append(self.rnn(z[:,:,i].view(batch_size,self.latent_size), encodings_arr[-1])) # Grabbing the most recent hidden state each time
        
        # encodings.shape is latent_seq_len, batch_size, 2*encoding_size
        encodings = torch.stack(encodings_arr)
        return encodings


class RnnEncoder(torch.nn.Module):
    # Original encoder for simulation data from TNC paper
    def __init__(self, hidden_size, in_channel, encoding_size, cell_type='GRU', num_layers=1, device='cpu', dropout=0, bidirectional=True):
        super(RnnEncoder, self).__init__()

        self.hidden_size = hidden_size # size of the hidden vector in the RNN
        self.in_channel = in_channel # number of features in the timeseries data?
        self.num_layers = num_layers
        self.cell_type = cell_type
        self.encoding_size = encoding_size # the size of the latent vector that will be generated
        self.bidirectional = bidirectional # Bidirectional RNNs allow the network to consider past and future time steps for each moment
        self.device = device

        # A linear layer that will come after the RNN part, and map to the encoding space (dimension encoding_size)
        # The input is the size of a hidden state (hidden_size) times 1 if the model is not bidirectional, and 2 if it is because if it is then
        # hidden vectors for forward and backward directions are concatinated.
        self.nn = torch.nn.Sequential(torch.nn.Linear(self.hidden_size*(int(self.bidirectional) + 1), self.encoding_size)).to(self.device)

        # Note batch_first=False just means the first dimension of the input won't be the batch size
        if cell_type=='GRU':
            self.rnn = torch.nn.GRU(input_size=self.in_channel, hidden_size=self.hidden_size, num_layers=num_layers,
                                    batch_first=False, dropout=dropout, bidirectional=bidirectional).to(self.device)

        elif cell_type=='LSTM':
            self.rnn = torch.nn.LSTM(input_size=self.in_channel, hidden_size=self.hidden_size, num_layers=num_layers,
                                    batch_first=False, dropout=dropout, bidirectional=bidirectional).to(self.device)
        else:
            raise ValueError('Cell type not defined, must be one of the following {GRU, LSTM, RNN}')

    def forward(self, x):
        if len(x.shape) == 4: # This means maps are passed in too, which are not needed for RNN
            x = x[:, 0, :, :]
        # x is either of shape (mc_sample_size, num_features, window_size) or (num_features, window_size)
        x = x.permute(2,0,1) # Moves around rows/columns. if old dim was (x, y, z), now its (z, x, y)
        if self.cell_type=='GRU':
            # Starting hidden vector of size (num_hidden_vectors_needed, batch_size, hidden_size). The number of hidden vectors needed will either be num_layers, or double that
            # if its bidirectional. Batch size is included because we want different hidden states for different sequences in a single batch. 
            past = torch.zeros(self.num_layers * (int(self.bidirectional) + 1), x.shape[1], self.hidden_size).to(self.device)
        elif self.cell_type=='LSTM':
            # Starting short term memory vector
            h_0 = torch.zeros(self.num_layers * (int(self.bidirectional) + 1), (x.shape[1]), self.hidden_size).to(self.device)
            # Starting long term memory vector
            c_0 = torch.zeros(self.num_layers * (int(self.bidirectional) + 1), (x.shape[1]), self.hidden_size).to(self.device)
            past = (h_0, c_0)
        out, _ = self.rnn(x.to(self.device), past)  # out shape = [seq_len, batch_size, num_directions*hidden_size]
        encodings = self.nn(out[-1].squeeze(0)) # squeeze gets rid of dimensions of size 1 on the 0 axis
        return encodings


class StateClassifier(torch.nn.Module):
    def __init__(self, input_size, output_size):
        super(StateClassifier, self).__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.normalize = torch.nn.BatchNorm1d(self.input_size)
        self.nn = torch.nn.Linear(self.input_size, self.output_size)
        torch.nn.init.xavier_uniform_(self.nn.weight)

    def forward(self, x):
        x = self.normalize(x)
        logits = self.nn(x)
        return logits


class WFClassifier(torch.nn.Module):
    def __init__(self, encoding_size, output_size):
        super(WFClassifier, self).__init__()
        self.encoding_size = encoding_size
        self.output_size = output_size
        self.classifier = nn.Linear(self.encoding_size, output_size)
        torch.nn.init.xavier_uniform_(self.classifier.weight)

    def forward(self, x):
        c = self.classifier(x)
        return c


class E2EStateClassifier(torch.nn.Module):
    '''End To End model. Its simply an RNN, either GRU or LSTM'''
    def __init__(self, hidden_size, in_channel, encoding_size, output_size, cell_type='GRU', num_layers=1, dropout=0,
                 bidirectional=True, device='cpu'):
        super(E2EStateClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.in_channel = in_channel
        self.num_layers = num_layers
        self.cell_type = cell_type
        self.encoding_size = encoding_size
        self.bidirectional = bidirectional
        self.output_size = output_size
        self.device = device

        self.fc = torch.nn.Sequential(torch.nn.Linear(self.hidden_size*(int(self.bidirectional) + 1), self.encoding_size)).to(self.device)
        self.nn = torch.nn.Sequential(torch.nn.Linear(self.encoding_size, self.output_size)).to(self.device)
        if cell_type=='GRU':
            self.rnn = torch.nn.GRU(input_size=self.in_channel, hidden_size=self.hidden_size, num_layers=num_layers,
                                    batch_first=False, dropout=dropout, bidirectional=bidirectional).to(self.device)
        elif cell_type=='LSTM':
            self.rnn = torch.nn.LSTM(input_size=self.in_channel, hidden_size=self.hidden_size, num_layers=num_layers,
                                    batch_first=False, dropout=dropout, bidirectional=bidirectional).to(self.device)
        else:
            raise ValueError('Cell type not defined, must be one of the following {GRU, LSTM, RNN}')

    def forward(self, x):
        # x is of shape (num_samples, num_features, signal_length)

        x = x.permute(2,0,1) # x is now of shape (signal_length, num_samples, num_features)
        if self.cell_type=='GRU':
            past = torch.zeros(self.num_layers * (int(self.bidirectional) + 1), x.shape[1], self.hidden_size).to(self.device)
        elif self.cell_type=='LSTM':
            h_0 = torch.zeros(self.num_layers * (int(self.bidirectional) + 1), (x.shape[1]), self.hidden_size).to(self.device)
            c_0 = torch.zeros(self.num_layers * (int(self.bidirectional) + 1), (x.shape[1]), self.hidden_size).to(self.device)
            past = (h_0, c_0)
        out, _ = self.rnn(x, past)  # out shape = [seq_len, batch_size, num_directions*hidden_size]
        encodings = self.fc(out[-1].squeeze(0))
        return self.nn(encodings)


class MimicEncoder(torch.nn.Module):
    def __init__(self, input_size, in_channel, encoding_size):
        super(MimicEncoder, self).__init__()
        self.input_size = input_size
        self.in_channel = in_channel
        self.encoding_size = encoding_size

        self.nn = torch.nn.Sequential(torch.nn.Linear(input_size, 64),
                                      torch.nn.Dropout(),
                                      torch.nn.ReLU(),
                                      torch.nn.Linear(64, encoding_size))

    def forward(self, x):
        x = torch.mean(x, dim=1)
        encodings = self.nn(x)
        return encodings


class WFEncoder(nn.Module):
    def __init__(self, encoding_size, classify=False, n_classes=None):
        # Input x is (batch, 2, 256)
        super(WFEncoder, self).__init__()

        self.encoding_size = encoding_size
        self.n_classes = n_classes
        self.classify = classify
        self.classifier =None
        if self.classify:
            if self.n_classes is None:
                raise ValueError('Need to specify the number of output classes for te encoder')
            else:
                self.classifier = nn.Sequential(
                    nn.Dropout(0.5),
                    nn.Linear(self.encoding_size, self.n_classes)
                )
                nn.init.xavier_uniform_(self.classifier[1].weight)

        self.features = nn.Sequential(
            nn.Conv1d(2, 64, kernel_size=4, stride=1, padding=1),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(64, eps=0.001),
            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(64, eps=0.001),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(128, eps=0.001),
            # nn.Dropout(),
            nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(128, eps=0.001),
            nn.MaxPool1d(kernel_size=2, stride=2),
            # nn.Dropout(0.5),
            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(256, eps=0.001),
            # nn.Dropout(0.5),
            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(256, eps=0.001),
            nn.MaxPool1d(kernel_size=2, stride=2)
            )

        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(79872, 2048),
            nn.ELU(inplace=True),
            nn.BatchNorm1d(2048, eps=0.001),
            nn.Linear(2048, self.encoding_size)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        encoding = self.fc(x)
        if self.classify:
            c = self.classifier(encoding)
            return c
        else:
            return encoding



# TRANSFORMER ENCODER. IMPLEMENTATION FROM https://timeseriesai.github.io/tsai//models.TST#TST 
# Based on this paper: https://arxiv.org/abs/2010.02803

class TST_pretrain_loader(data.Dataset):
    '''Loader used in the pretraining method'''
    def __init__(self, x, mask) -> None:
        super().__init__()
        self.x = x
        self.mask = mask
        if tuple(x.shape) != tuple(mask.shape):
            raise ValueError("x and mask must be of identical dimensions")
        
    def __len__(self):
        return len(self.x)
    def __getitem__(self, ind):
        return (self.x[ind], self.mask[ind])

# Internal Cell
class _ScaledDotProductAttention(torch.nn.Module):
    def __init__(self, d_qk:int): 
        super(_ScaledDotProductAttention, self).__init__()
        self.d_qk = d_qk
    def forward(self, q:torch.Tensor, k:torch.Tensor, v:torch.Tensor, mask:torch.Tensor=None, masked_val:int=1e-9):

        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence
        scores = torch.matmul(q, k)                                         # scores : [bs x n_heads x q_len x q_len]

        # Scale
        scores = scores / (self.d_qk ** 0.5)

        if mask is not None:
            # mask is size (bs, num_features, seq_len)
            num_features = mask.shape[1]
            mask = torch.sum(mask, dim=1) # mask is now of shape (bs, seq_len)
            mask = torch.max(mask-num_features/2, torch.zeros_like(mask)) # Subtract num_features/2: We'll allow half of features to be missing before decreasing context value
            mask = mask/(num_features)
            mask = 1-mask
            bs = mask.shape[0]
            seq_len = mask.shape[1]
            for i in range(bs):
                scores[i, :] = scores[i, :] * mask[i].view([seq_len, 1])

        # Mask (optional)
        # if mask is not None: scores.masked_fill_(mask==1, masked_val)

        # SoftMax
        attn = torch.nn.functional.softmax(scores, dim=3)                   # attn   : [bs x n_heads x q_len x q_len]

        # MatMul (attn, v)
        context = torch.matmul(attn, v)                                     # context: [bs x n_heads x q_len x d_v]
        


        return context, attn

# Internal Cell
class _MultiHeadAttention(torch.nn.Module):
    def __init__(self, hidden_size:int, n_heads:int, d_qk:int, d_v:int):
        super(_MultiHeadAttention, self).__init__()
        self.n_heads, self.d_qk, self.d_v = n_heads, d_qk, d_v

        self.W_Q = nn.Linear(hidden_size, d_qk * n_heads, bias=False)
        self.W_K = nn.Linear(hidden_size, d_qk * n_heads, bias=False)
        self.W_V = nn.Linear(hidden_size, d_v * n_heads, bias=False)

        # Linear layer that condenses the multiple heads of attention. Takes in the vector of combined heads (dimension n_heads*d_v) 
        # and converts down to hidden_size for the next attention head
        # Note: I believe this is W^O from the illustrated transformer article, *not* the W_O from the paper this code is based on
        self.W_O = nn.Linear(n_heads * d_v, hidden_size, bias=False)

    def forward(self, Q:torch.Tensor, K:torch.Tensor, V:torch.Tensor, mask:torch.Tensor=None, mask_val:float=1e-9):
        r"""
        Q, K, and V are all passed in as just the input sequence of data
        Input shape:  Q, K, V:[batch_size (bs) x q_len x hidden_size], 
                         mask:[q_len x q_len]
        """

        bs = Q.size(0)
        q_len = Q.shape[1]

        # Linear (+ split in multiple heads)
        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_qk).transpose(1,2)       # q_s    : [bs x n_heads x q_len x d_qk]
        assert tuple(q_s.shape) == (bs, self.n_heads, q_len, self.d_qk)

        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_qk).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_qk x q_len] - transpose(1,2) + transpose(2,3)
        assert tuple(k_s.shape) == (bs, self.n_heads, self.d_qk, q_len)

        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]
        assert tuple(v_s.shape) == (bs, self.n_heads, q_len, self.d_v)

        # Scaled Dot-Product Attention (multiple heads)
        context, attn = _ScaledDotProductAttention(self.d_qk)(q_s, k_s, v_s, mask, mask_val)          # context: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len]

        # Concat
        # Note: contiguous just makes context behave in memory as if it had always been of this shape. Transpose doesn't actually modify the tensor, just adjusts meta data
        context = context.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # context: [bs x q_len x n_heads * d_v]
        # Note: a -1 for dim1 tells torch to make dim1 whatever value allows it to satisfy dim0, and dim2

        # Linear
        output = self.W_O(context)                                                  # context is now of shape: [bs x q_len x hidden_size]

        return output, attn

# Internal Cell
class _TSTEncoderLayer(torch.nn.Module):
    def __init__(self, q_len:int, hidden_size:int, n_heads:int, d_qk:int=None, d_v:int=None, d_ff:int=256, res_dropout:float=0.1,
                 activation:str="gelu"):
        super(_TSTEncoderLayer, self).__init__()
        #assert hidden_size // n_heads, f"hidden_size ({hidden_size}) must be divisible by n_heads ({n_heads})"
        #assert not hidden_size%n_heads # if n_heads divides hidden_size, then the mod is 0, so assert not(0) = assert 1 = True

        if d_qk is None:
            d_qk = hidden_size // n_heads
        if d_v is None:
            d_v = hidden_size // n_heads
        #d_qk = ifnone(d_qk, hidden_size // n_heads)
        #d_v = ifnone(d_v, hidden_size // n_heads)

        # Multi-Head attention
        self.self_attn = _MultiHeadAttention(hidden_size, n_heads, d_qk, d_v)

        # Add & Norm
        self.dropout_attn = nn.Dropout(res_dropout)
        self.batchnorm_attn = nn.BatchNorm1d(q_len)

        # Position-wise Feed-Forward
        self.ff = nn.Sequential(nn.Linear(hidden_size, d_ff), self._get_activation_fn(activation), nn.Linear(d_ff, hidden_size))

        # Add & Norm
        self.dropout_ffn = nn.Dropout(res_dropout)
        self.batchnorm_ffn = nn.BatchNorm1d(q_len)

    def forward(self, src:torch.Tensor, mask:torch.Tensor=None, mask_val:float=1e-9) -> torch.Tensor:

        # Multi-Head attention sublayer
        ## Multi-Head attention
        src2, attn = self.self_attn(src, src, src, mask=mask, mask_val=mask_val)
        ## Add & Norm
        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout
        src = self.batchnorm_attn(src)      # Norm: batchnorm

        # Feed-forward sublayer
        ## Position-wise Feed-Forward
        src2 = self.ff(src)
        ## Add & Norm
        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout
        src = self.batchnorm_ffn(src) # Norm: batchnorm

        return src

    def _get_activation_fn(self, activation):
        if activation == "relu": return nn.ReLU()
        elif activation == "gelu": return nn.GELU()
        else: return activation()
#         raise ValueError(f'{activation} is not available. You can use "relu" or "gelu"')

# Internal Cell
class _TSTEncoder(torch.nn.Module):
    def __init__(self, q_len, hidden_size, n_heads, d_qk=None, d_v=None, d_ff=None, res_dropout=0.1, activation='gelu', n_layers=1):
        super(_TSTEncoder, self).__init__()
        self.layers = nn.ModuleList([_TSTEncoderLayer(q_len, hidden_size, n_heads=n_heads, d_qk=d_qk, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout,
                                                            activation=activation) for i in range(n_layers)])

    def forward(self, src, mask, mask_val):
        output = src
        for module in self.layers: output = module(output, mask, mask_val)
        return output


# Cell
class TST(nn.Module):
    def __init__(self, num_features:int, encoding_size:int, seq_len:int, max_seq_len:int=None,
                 n_layers:int=3, hidden_size:int=128, n_heads:int=16, d_qk:int=None, d_v:int=None,
                 d_ff:int=256, res_dropout:float=0.1, act:str="gelu", fc_dropout:float=0.,
                 y_range:tuple=None, verbose:bool=False, device='cpu', **kwargs):
        r"""TST (Time Series Transformer) is a Transformer that takes continuous time series as inputs.
        As mentioned in the paper, the input must be standardized by_var based on the entire training set.
        Args:
            num_features: the number of features (aka variables, dimensions, channels) in the time series dataset.
            encoding_size: The dimension of the final encoding. If this is 10, then the model outputs 10 dimensional vectors.
            seq_len: number of time steps in the time series.
            max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues.
            hidden_size: The dimension of the vectors going through the attention layers. This is the d refernced in Figure 1 (Left)
            n_heads:  parallel attention heads.
            d_qk: size of the learned linear projection of queries and keys in the MHA (Multi Headed Attention). Usual values: 16-512. Default: None -> (hidden_size/n_heads) = 32.
            d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (hidden_size/n_heads) = 32.
            d_ff: the dimension of the feedforward network model.
            res_dropout: amount of residual dropout applied in the encoder.
            act: the activation function of intermediate layer, relu or gelu.
            num_layers: the number of sub-encoder-layers in the encoder.
            fc_dropout: dropout applied to the final fully connected layer.
            y_range: range of possible y values (used in regression tasks).
            kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.
        Input shape:
            bs (batch size) x num_features (aka features, variables, dimensions, channels) x seq_len (aka time steps)
        """
        super(TST, self).__init__()

        self.encoding_size, self.seq_len = encoding_size, seq_len
        self.hidden_size, self.fc_dropout = hidden_size, fc_dropout
        self.device = device
        
        

        # Input encoding
        q_len = seq_len
        self.new_q_len = False
        if max_seq_len is not None and seq_len > max_seq_len: # Control temporal resolution
            self.new_q_len = True
            q_len = max_seq_len
            tr_factor = math.ceil(seq_len / q_len)
            total_padding = (tr_factor * q_len - seq_len)
            padding = (total_padding // 2, total_padding - total_padding // 2)
            self.W_P = nn.Sequential(torch.nn.ConstantPad1d(padding), torch.nn.Conv1d(num_features, hidden_size, kernel_size=tr_factor, stride=tr_factor))

            if verbose:
                print(f'temporal resolution modified: {seq_len} --> {q_len} time steps: kernel_size={tr_factor}, stride={tr_factor}, padding={padding}.\n')
        elif kwargs:
            self.new_q_len = True
            t = torch.rand(1, 1, seq_len)
            q_len = nn.Conv1d(1, 1, **kwargs)(t).shape[-1]
            self.W_P = nn.Conv1d(num_features, hidden_size, **kwargs) # Eq 2
            if verbose:
                print(f'Conv1d with kwargs={kwargs} applied to input to create input encodings\n')
        else:
            self.W_P = nn.Linear(num_features, hidden_size).to(self.device) # Eq 1: projection of feature vectors onto a d-dim vector space

        # Positional encoding
        W_pos = torch.zeros((q_len, hidden_size), device=device) # Idea: Maybe initialize as non zero?
        # W_pos = torch.randn((q_len, hidden_size), device=device) # positional encoding
        self.W_pos = nn.Parameter(W_pos, requires_grad=True)

        # Residual dropout
        self.res_dropout = nn.Sequential(nn.Dropout(res_dropout)).to(self.device)

        # Encoder
        self.encoder = _TSTEncoder(q_len, hidden_size, n_heads, d_qk=d_qk, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, activation=act, n_layers=n_layers).to(self.device)


        # This is just a ff layer that converts to the encoding size
        layers = [nn.Dropout(self.fc_dropout)] if self.fc_dropout else []
        layers += [nn.Linear(self.hidden_size*self.seq_len, self.encoding_size)]
        # Note *layers just unpacks layers and passes them in as parameters for nn.Sequential
        self.linear_hidden_to_encoding = nn.Sequential(*layers).to(self.device)

        # Head
        #self.head_num_features = q_len * hidden_size
        #self.head = self.create_head(self.head_num_features, encoding_size, fc_dropout=fc_dropout)

        # Linear layer used in pretraining. Converts from encoding_size to num_features*seq_len
        # e.g. take 10D encoding, map to 120D output which will get reshaped to (3, 40) = (num_features, seq_len). There's a 3rd dim for batches tho
        self.linear_for_pretraining = nn.Linear(self.encoding_size, num_features*seq_len).to(self.device) 

    

    def forward(self, data: torch.Tensor, mask_val:float=1e-9, mask_included=True) -> torch.Tensor:  # x: (bs, nvars, q_len])
        data = data.to(self.device)
        if len(tuple(data.shape)) == 3 and mask_included: # Only a single sample is being passed in
            data = data.unsqueeze(0) # Add dim 1 at the start so its a 'batch' of size 1.
        elif len(tuple(data.shape)) == 2 and not mask_included: # In this case 1 sample is being passed in with data that doesn't have mask channel
            data = data.unsqueeze(0) # data is now shape (1, num_features, seq_len)
        if data.shape[1] == 2:
            x = data[:, 0, :, :]
            mask = data[:, 1, :, :] # If dim 1 has 2 channels, its implied that this is for mask
        else:
            x = data
            mask = None
        # mask is a tensor where 1's indicate values in our data that were initially NaN. mask_val is the attention value we attribute for such values. If we replaced NaNs with 0's, then a low
        # value for mask_val such as 1e-9 makes sense, but if we took efforts to impute intelligently then we may want to use something larger (1/seq_len) so that it still has some impact.

        # x is of shape (batch_size, num_features, seq_len)
        x = x.float()
        # Input encoding
        #if self.new_q_len: u = self.W_P(x).transpose(2,1) # Eq 2        # u: (bs, hidden_size, q_len) transposed to (bs, seq_len, hidden_size)
        #else: 

        # x transpose makes x of shape (batch_size, seq_len, num_features)
        u = self.W_P(x.transpose(2,1)) # Eq 1                     # u: (bs, num_features,  seq_len) converted to (bs, seq_len, hidden_size)

        # Positional encoding
        u = self.res_dropout(u + self.W_pos) # element wise addition with positional encoding vector

        # Encoder
        z = self.encoder(u, mask, mask_val)                             # z: (bs, q_len, hidden_size)
        z = z.view(z.size(0), -1)     # flattening                      # z: (bs, q_len * hidden_size)
        #else: z = z.transpose(2,1).contiguous()                         # z: (bs, hidden_size, q_len)

        
        return self.linear_hidden_to_encoding(z)    # return is of size (bs, encoding_size)
    
    def pretrain(self, x:torch.Tensor, lr: float, decay: float, batch_size: int, num_epochs:int=50):
        # x is of shape (num_train_samples, 2, num_features, signal_length), assume its been shuffled and
        # that we are passing in only *training* data
        x = x[:, 0, :, :]

        # Masking + pretrain implemented according to the paper
        
        r = 0.15 # prob of setting a value to 0

        l_m = 3 # mean len of a segment of 0's
        # Recall for a geometric dist., mean=(1-p)/p, where p defines the geom dist.
        p_0 = 1/(1+l_m) # p_0 is the value that defines the geom dist of lengths of seq's of 0's

        l_u = ((1-r)/r)*l_m  # mean len of a segment of 1's
        p_1 = 1/(1+l_u) # p_1 is the value that defines the geom dist of lengths of seq's of 1's

        # Recall x is of shape (num_samples, num_features, seq_len])
        # We must reshape it though because seq_len could be large (e.g. 2000) when we pass in the whole dataset to pretrain,
        # but the learnable parameters in the transformer are built to deal with sequences of length window_size (i.e. self.seq_len)
        x = torch.Tensor(x)
        x = torch.reshape(x, (-1, x.shape[1], self.seq_len))
        num_train_samples, num_features, seq_len = x.shape

        mask = torch.ones(x.shape)
        
        start_indices = torch.zeros((num_train_samples, num_features))


        # done_values are booleans indicating if we've finished masking for the ij'th sequence, where i and j
        # are in the range of num_train_samples and num_features respectively. 0=Done Masking, 1=Not Done
        done_values = torch.ones((num_train_samples, num_features))
        while True:
            items, counts = torch.unique(done_values, return_counts=True)
            if counts[0] == num_train_samples*num_features and 0  in items: # done_values is filled with 0's
                break
            
            for i in range(num_train_samples):
                for j in range(num_features):
                    if done_values[i][j] == 1:
                        one_seg_length = np.random.geometric(p_1)
                        mask[i, j, int(start_indices[i][j]): min(seq_len, int(start_indices[i][j]+one_seg_length * done_values[i][j]))] = 1
                        start_indices[i][j] += one_seg_length * done_values[i][j]
                        if start_indices[i][j] > seq_len:
                            done_values[i][j] = 0
                    
                    if done_values[i][j] == 1:
                        zero_seg_length = np.random.geometric(p_0)
                        mask[i, j, int(start_indices[i][j]): min(seq_len, int(start_indices[i][j]+zero_seg_length * done_values[i][j]))] = 0
                        start_indices[i][j] += zero_seg_length * done_values[i][j]
                        if start_indices[i][j] > seq_len:
                            done_values[i][j] = 0

        loss_fn = torch.nn.MSELoss()
        params = list(self.parameters())
        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=decay)
        loss_progression = []
        
        for epoch in range(num_epochs):
            epoch_loss = 0
            
            batches = TST_pretrain_loader(x, mask)
            batches = data.DataLoader(batches, batch_size=batch_size, shuffle=True, num_workers=3) # Wrap in DataLoader so we can have batches
            
            for truth_batch, mask_batch in batches:
                optimizer.zero_grad()
                truth_batch = truth_batch.to(self.device)
                mask_batch = mask_batch.to(self.device)
                masked = truth_batch * mask_batch # apply the mask
                masked = masked.float()
                z = self.forward(masked) # z is of shape (bs, encoding_size)
                
                reconstruction = self.linear_for_pretraining(z)
                reconstruction = torch.reshape(reconstruction, (batch_size, num_features, seq_len))
    
                # Measure reconstruction loss only for the masked values
                mask_batch = mask_batch.cpu() # Need to move back to CPU for np.where to work
                loss = loss_fn(reconstruction[np.where(mask_batch==0)], truth_batch[np.where(mask_batch==0)])
                epoch_loss += loss.item()
                
                loss.backward()
                optimizer.step()

            loss_progression.append(epoch_loss/batch_size)

        print('loss progression during Transformer pretraining:')
        print(loss_progression)
            



# END OF TRANSFORMER ENCODER CODE 



# GRU-D 

class FilterLinear(nn.Module):
    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):
        '''
        filter_square_matrix : identity matrix of shape (in_features, in_features)
        '''
        super(FilterLinear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features

        #use_gpu = torch.cuda.is_available()
        use_gpu = False
        self.filter_square_matrix = None
        if use_gpu:
            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)
        else:
            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)

        self.weight = Parameter(torch.Tensor(out_features, in_features))
        if bias:
            self.bias = Parameter(torch.Tensor(out_features))
        else:
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        stdv = 1. / math.sqrt(self.weight.size(1))
        self.weight.data.uniform_(-stdv, stdv)
        if self.bias is not None:
            self.bias.data.uniform_(-stdv, stdv)

    #         print(self.weight.data)
    #         print(self.bias.data)

    def forward(self, input):
        #         print(self.filter_square_matrix.mul(self.weight))
        return torch.nn.functional.linear(input, self.filter_square_matrix.mul(self.weight), self.bias)

    def __repr__(self):
        return self.__class__.__name__ + '(' \
               + 'in_features=' + str(self.in_features) \
               + ', out_features=' + str(self.out_features) \
               + ', bias=' + str(self.bias is not None) + ')'


class GRUD(nn.Module):
    def __init__(self, num_features, hidden_size, device='cpu', output_last=False):
        """
        Recurrent Neural Networks for Multivariate Times Series with Missing Values
        GRU-D: GRU exploit two representations of informative missingness patterns, i.e., masking and time interval.
        cell_size is the size of cell_state.
        Implemented based on the paper:
        @article{che2018recurrent,
          title={Recurrent neural networks for multivariate time series with missing values},
          author={Che, Zhengping and Purushotham, Sanjay and Cho, Kyunghyun and Sontag, David and Liu, Yan},
          journal={Scientific reports},
          volume={8},
          number={1},
          pages={6085},
          year={2018},
          publisher={Nature Publishing Group}
        }
        GRU-D:
            num_features: number of features being measured at each time step
            hidden_size: dimension of hidden_state at each time step
            mask_size: dimension of masking vector at each time step
            X_mean: the mean of the historical input data
        """

        super(GRUD, self).__init__()

        self.hidden_size = hidden_size
        self.delta_size = num_features
        self.mask_size = num_features

        
        
        self.identity = torch.eye(num_features).to(device)
        self.zeros = Variable(torch.zeros(num_features)).to(device)
        self.zeros_h = Variable(torch.zeros(self.hidden_size)).to(device)

        self.zl = nn.Linear(num_features + hidden_size + self.mask_size, hidden_size).to(device) # Update gate weights. W_z, U_z, V_z from the paper concatenated into one big matrix
        self.rl = nn.Linear(num_features + hidden_size + self.mask_size, hidden_size).to(device) # Reset gate weights. W_r, U_r, V_r from the paper concatenated into one big matrix
        self.hl = nn.Linear(num_features + hidden_size + self.mask_size, hidden_size).to(device) # Hidden state weights. W, U, and V from the paper concatenated into one big matrix
       
        # self.gamma_x_l is of shape (num_features, num_features)
        self.gamma_x_l = FilterLinear(self.delta_size, self.delta_size, self.identity).to(device) # Decay for input data. Missing data will decay from 
        # the last observed value towards the emprical mean


        self.gamma_h_l = nn.Linear(self.delta_size, self.hidden_size).to(device) # Decay for the hidden states. This is applied
        # Before going through the gates of the GRU. As per the paper, the matrix is not forced to be diagonal, whereas it is for gamma_x_l

        self.output_last = output_last

    def step(self, x, x_last_obsv, x_mean, h, mask, delta):
        # Note: mask is assumed to be of format where 1 indicates observed and 0's indicate missingness
        # x, x_last_obsv, x_mean, mask, and delta are of shape (batch_size, num_features)
        # Hidden_State is of shape (batch_size, self.hidden_size)

        # batch_size = x.shape[0]
        # num_features = x.shape[1]

        # Compute decays
        
        
        assert not torch.isnan(x).any()
        assert not torch.isnan(x_last_obsv).any()
        assert not torch.isnan(x_mean).any()
        assert not torch.isnan(h).any()
        assert not torch.isnan(mask).any()
        assert not torch.isnan(delta).any()
        
        delta_x = torch.exp(-torch.max(self.zeros, self.gamma_x_l(delta))) # self.zeros is of shape (num_features), self.gamma_x_l(delta) is of shape (batch_size, num_features)
        
        delta_h = torch.exp(-torch.max(self.zeros_h, self.gamma_h_l(delta))) # self.zeros_h is of shape (self.hidden_size), self.gamma_h_l(delta) is of shape (batch_size, self.hidden_size)
        assert not torch.isnan(delta_x).any()
        assert not torch.isnan(delta_h).any()

        # Apply decays to input data and hidden state
        x = mask * x + (1 - mask) * (delta_x * x_last_obsv + (1 - delta_x) * x_mean)
        assert not torch.isnan(x).any()
        h = delta_h * h
        assert not torch.isnan(h).any()

        
        # Concatenate x, h, and mask so they can go into zl, rl, and hl which each are matrices of concatenated
        # W's, U's and V's
        combined = torch.cat((x, h, mask), 1) # Think of x, h, and mask being put side to side. combined is of shape (batch_size, num_features + self.hidden_size + num_features)
        z = torch.sigmoid(self.zl(combined)) # z is of shape (batch_size, self.hidden_size)
        r = torch.sigmoid(self.rl(combined)) # r is of shape (batch_size, self.hidden_size)

        # Compute h tilde
        combined_r = torch.cat((x, r * h, mask), 1) # combined_r is of shape (batch_size, num_features + self.hidden_size + num_features)
        
        h_tilde = torch.tanh(self.hl(combined_r)) # h_tilde is of shape (batch_size, self.hidden_size)
        
        h = (1 - z) * h + z * h_tilde

        # print('end: ', h.shape)
        return h

    def forward(self, X, Mask, X_last_obsv, Delta, X_mean):
        #batch_size = input.size(0) # Size of each batch
        #type_size = input.size(1) # 0'th value in this dim is data, 1st is last observed data, second is mask, third is delta (time since last observation)
        # step_size = input.size(2) # Not sure what this is for.. just set this dim to 1
        # spatial_size = input.size(3) # Not sure what this is for, set to 1


        # X is of shape (batch_size, num_features, seq_len). Its our data
        # Mask is of shape (batch_size, num_features, seq_len). Its a mask of our data. 1's indicate observed, 0's indicate missing
        # X_last_obsv is of shape (batch_size, num_features, seq_len). Its a tensor of the last observed value for each feature at each time step, for each batch.
        # Delta is of shape (batch_size, num_features, seq_len). Its the time since the last observed value for each feature at each time step, for each batch.
        # X_mean is of shape (batch_size, num_features). The ij'th element is the average observed value of the j'th feature for the i'th batch


        batch_size = X.shape[0]
        num_features = X.shape[1]
        seq_len = X.shape[2]

        Hidden_State = self.initHidden(batch_size) # Creates 0 matrix of shape (batch_size, self.hidden_size). There will be a self.hidden_size vector for each multivariate time series in the batch.
        #X = torch.squeeze(input[:, 0, :, :]) # X is of shape (batch_size, step_size, seq_len)
        #X_last_obsv = torch.squeeze(input[:, 1, :, :])
        #Mask = torch.squeeze(input[:, 2, :, :])
        #Delta = torch.squeeze(input[:, 3, :, :])


        #if input.shape[0]==1: # If batch size is 1 (i.e. passing in a single sample)
        #    X = X.unsqueeze(0)
        #    X_last_obsv = X_last_obsv.unsqueeze(0)
        #    Mask = Mask.unsqueeze(0)
        #    Delta = Delta.unsqueeze(0)

        # print('The slice', X.shape, self.delta_size)

        # use_gpu = torch.cuda.is_available()
        # X_mean = torch.zeros((len(input), self.delta_size)) # (num_samples, num_features)
        #if use_gpu:
        #    X_mean = X_mean.to('cuda')

        outputs = []
        for i in range(seq_len):
            Hidden_State = self.step(X[:, :, i], # all of the parameters to self.step are of shape (batch_size, num_features), except Hidden_State which is of shape (batch_size, self.hidden_size)
                                     X_last_obsv[:, :, i],
                                     X_mean,
                                     Hidden_State,
                                     Mask[:, :, i],
                                     Delta[:, :, i])
            
            # Hidden_State is of shape (batch_size, self.hidden_size)
            
            
            outputs.append(Hidden_State)

        outputs = torch.stack(outputs) # outputs is of shape (seq_len, batch_size, hidden_size). i.e. for each time step, we have a matrix of hidden states, one for each sample from our batch.
        if self.output_last:
            return outputs[-1, :, :]
        else:
            return outputs

    def initHidden(self, batch_size):
        use_gpu = torch.cuda.is_available()
        if use_gpu:
            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())
            return Hidden_State
        else:
            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))
            return Hidden_State





class GRUDEncoder(nn.Module):
    '''Encodes time series data using GRUD cells'''
    def __init__(self, num_features, hidden_size, num_layers, encoding_size, extra_layer_types, dropout=0, device='cpu') -> None:
        super(GRUDEncoder, self).__init__()
        self.num_features = num_features
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.device = device
        self.encoding_size = encoding_size
        self.extra_layer_types = extra_layer_types
        
        self.layers=[]
        self.layers.append(GRUD(num_features=num_features, hidden_size=hidden_size, device=device, output_last=False))

        if num_layers > 1:
            if extra_layer_types=='GRU':
                self.layers.append(torch.nn.GRU(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=num_layers-1,
                                        batch_first=False, dropout=dropout).to(self.device))
            # batch_first being False means input is of shape (seq_len, batch_size, hidden_size) which is the form GRUD outputs
            elif extra_layer_types=='LSTM':
                self.layers.append(torch.nn.LSTM(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=num_layers-1,
                                        batch_first=False, dropout=dropout).to(self.device))
            else:
                raise ValueError('Cell type not defined, must be one of the following {GRU, LSTM}')

        self.linear = torch.nn.Sequential(torch.nn.Linear(self.hidden_size, 50),
                                          torch.nn.Dropout(dropout),
                                          torch.nn.ReLU(),
                                          torch.nn.Linear(50, encoding_size)).to(self.device)

    def forward(self, X):
        if len(tuple(X.shape)) == 3: # If we have a single sample being passed in
            X = X.unsqueeze(0) # Make it of shape (1, 2, num_features, seq_len)
        
        map = X[:, 1, :, :] # map is set up so 1's indicate missingness 0's indicate observed
        Delta = torch.ones_like(map).to(self.device)
        for i in range(1, map.shape[2]): # map is of shape (num_samples, num_feautres, seq_len). i iterates through time steps
            places_to_modify = map[:, :, i].bool()
            Delta[:, :, i][places_to_modify] = Delta[:, :, i-1][places_to_modify] + 1


        X = X[:, 0, :, :].to(self.device)

        Mask = (1-map).to(self.device) # Mask is now of the format where 0's indicate missingness and 1's indicate observed values

        # Compute means:
        sums = torch.sum(X*Mask, 2)
        counts = torch.sum(Mask, 2)
        counts[counts==0] = 1 # Ensure we don't divide by 0!
        X_mean = (sums/counts).to(self.device) # Comptues mean for each sample and feature over time.

        X_last_obsv = X.to(self.device) # Since we forward imputeted our data

        # X is of shape (batch_size, num_features, seq_len). Its our data
        # Mask is of shape (batch_size, num_features, seq_len). Its a mask of our data. 1's indicate observed, 0's indicate missing
        # X_last_obsv is of shape (batch_size, num_features, seq_len). Its a tensor of the last observed value for each feature at each time step, for each sample in the batch.
        # Delta is of shape (batch_size, num_features, seq_len). Its the time since the last observed value for each feature at each time step, for each sample in the batch.
        # X_mean is of shape (batch_size, num_features). The ij'th element is the average observed value of the j'th feature for the i'th sample in the batch
        X = self.layers[0](X, Mask, X_last_obsv, Delta, X_mean)
        
        if self.extra_layer_types=='GRU':
            # Starting hidden vector of size (num_layers, batch_size, hidden_size). The number of hidden vectors needed will either be num_layers, or double that
            # if its bidirectional. Batch size is included because we want different hidden states for different sequences in a single batch. 
            past = torch.zeros(self.num_layers, X.shape[1], self.hidden_size).to(self.device)
        elif self.extra_layer_types=='LSTM':
            # Starting short term memory vector
            h_0 = torch.zeros(self.num_layers, X.shape[1], self.hidden_size).to(self.device)
            # Starting long term memory vector
            c_0 = torch.zeros(self.num_layers, X.shape[1], self.hidden_size).to(self.device)
            past = (h_0, c_0)
        if self.num_layers > 1:
            out, _ = self.layers[1](X.to(self.device), past)  # out shape = [seq_len, batch_size, hidden_size]. 
            encodings = self.linear(out[-1]) # Gets the (batch_size, hidden_size) matrix from the last time step
        else:
            encodings = self.linear(X[-1])
        return encodings


class LinearClassifier(nn.Module):
    def __init__(self, input_size):
        super(LinearClassifier, self).__init__()
        self.input_size = input_size
        
        self.classifier = nn.Sequential(nn.Linear(self.input_size, 8),
                                        nn.ReLU(),
                                        nn.Dropout(p=0.3),
                                        nn.Linear(8, 1),
                                        nn.Dropout(p=0.3))
        torch.nn.init.xavier_uniform_(self.classifier[0].weight)
        torch.nn.init.xavier_uniform_(self.classifier[3].weight)

    def forward(self, x):
        logits = self.classifier(x.view(x.size(0), -1))
        return logits

    def predict_proba(self, x):
        '''
        For compatibility with Sklearn
        '''
        logits = self.classifier(x.view(x.size(0), -1))
        return logits





class RnnPredictor(torch.nn.Module):
    def __init__(self, encoding_size, hidden_size, n_classes=1):
        super(RnnPredictor, self).__init__()
        self.encoding_size = encoding_size
        self.hidden_size = hidden_size
        self.num_layers = 1
        self.rnn = torch.nn.LSTM(input_size=encoding_size,  hidden_size=hidden_size, num_layers=self.num_layers, batch_first=True)
        if n_classes == 1:
            self.linear = torch.nn.Linear(hidden_size, n_classes)
        else:
            self.linear = torch.nn.Sequential(torch.nn.Linear(hidden_size, 32), 
                                              torch.nn.Linear(32, n_classes))

    def forward(self, x, return_full_seq=False):
        # x is of shape (num_samples, seq_len, num_features)
        output, (h_n, _) = self.rnn(x)
        preds = []
        for hidden_states in output:
            preds.append(self.linear(hidden_states).squeeze()) # of shape (seq_len, num_classes)
        
        # of shape (num_samples, seq_len, n_classes) or (num_samples, seq_len) if n_classes ==1. The ijk'th element is the prediction of class k for sample i at time j
        preds = torch.stack(preds) # Note this must be passed through sigmoid after output
        if return_full_seq:
            return preds
        else:
            return preds[:, -1] # of shape (num_samples, n_classes)

        




class CNN_Transformer_Encoder(nn.Module):
    # CNN transforms data both in the time and feature dimensions, then a transformer summarizes
    def __init__(self, latent_size, encoding_size, in_channel, transformer_n_layers, transformer_hidden_size, transformer_n_heads, transformer_d_ff, transformer_res_dropout, transformer_act, transformer_fc_dropout, device='cpu'):
        """
        Encoder of patient condition into lower dimensional encoding space, using time series signals.
        First layer convolution extracts features into a latent variable, which feeds into an RNN to
        generate the encoding
        :param latent_size: size of the latent paramteters generated by the CNN
        :param encoding_size: Size of the final encoding
        """
        super(CNN_Transformer_Encoder, self).__init__()
        self.latent_size = latent_size
        self.encoding_size = encoding_size
        self.in_channel = in_channel # This will be 2, for data and maps
        out_channel = self.latent_size
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.transformer_n_layers = transformer_n_layers
        self.transformer_hidden_size = transformer_hidden_size
        self.transformer_n_heads = transformer_n_heads
        self.transformer_d_ff = transformer_d_ff
        self.transformer_res_dropout = transformer_res_dropout
        self.transformer_act = transformer_act
        self.transformer_fc_dropout = transformer_fc_dropout
        
        self.conv = nn.Sequential(nn.Conv2d(in_channels=self.in_channel, out_channels=32, padding=0, kernel_size=(1, 3)),
                                  # nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=32),
                                  nn.Conv2d(in_channels=32, out_channels=64, padding=0, kernel_size=(1, 3)),
                                  nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=64),
                                  nn.Conv2d(in_channels=64, out_channels=32, padding=0, kernel_size=(8, 3)), # changed kernel_size from (10,4) to (8,4) so data with 8 features will lead to output dim c = 1 (see comment below)
                                  nn.MaxPool2d(kernel_size=(1, 2)),
                                  nn.ReLU(),
                                  nn.Dropout(0.5),
                                  nn.BatchNorm2d(num_features=32),
                                  nn.Conv2d(in_channels=32, out_channels=self.latent_size, kernel_size=(1, 3)),
                                  nn.ReLU())
        #==

        # Output of the convolutional layers is of shape (a, b, c, d). a=batch size, b=self.latent_size, c=1, d is determined by data dimension, kernel sizes, and stride, but is 
        # essentially representing the time dimension. So as the input we had data of shape (num_features, seq_len), and now our latent states are of shape (latent_size, d), 
        # where latent_size <= num_features, and d <= seq_len (although in most cases these will probably be < not <=)



        # input is of size latent_size, output is of size 2*self.encoding_size
        self.transformer = None # Will define in get_distribution_params
        
        
        # Parameters of the posterior distribution of the latent representation
        self.mus = torch.nn.Sequential(nn.Linear(2 * self.encoding_size, self.encoding_size))
        self.cov = torch.nn.Sequential(torch.nn.Linear(2 * self.encoding_size, self.encoding_size),
                                       torch.nn.ReLU())

        torch.nn.init.xavier_uniform_(self.mus[0].weight)
        torch.nn.init.xavier_uniform_(self.cov[0].weight)

    def forward(self, x, kl_loss=False, past_state=None):
        # x is of shape (num_samples, 2, num_features, signal_length)
        if len(tuple(x.shape)) == 3: # if a single window is being passed in
            x = x.unsqueeze(0) # Make it a batch size of 1 so its 4 dimensional.
        hiddens = self.get_distribution_params(x) # Shape: latent_seq_len, batch_size, 2*encoding_size


        mus = self.mus(hiddens) 
        std = self.cov(hiddens) # mus and std are each of shape (batch_size, encoding_size)
        
        kl_z = 0.5 * (torch.bmm(mus.unsqueeze(1), mus.unsqueeze(-1)) + torch.bmm(std.unsqueeze(1), std.unsqueeze(-1)) - \
                      mus.shape[-1] - torch.sum(torch.log((std+1e-5) ** 2), -1)) # What's going on here?

        if kl_loss:
            return mus + std * torch.randn(std.shape).to(self.device), kl_z

        return mus + std * torch.randn(std.shape).to(self.device) # Doesn't return a distribution, returns a sample of the distribution.


    def get_distribution_params(self, x, past_state=None):
        
        x = x.to(self.device)
        
        z = self.conv(x) # Latent state of shape (batch_size, latent_size, 1, latent_seq_len), where latent_seq_len is the compressed time dimension
        z = z.squeeze(2) # remove the dimension of size 1
        batch_size, latent_size, latent_seq_len = z.shape
        if self.transformer is None: # If we haven't instantiated the transformer yet, do so using the dimensions of z
            self.transformer = TST(num_features=self.latent_size, encoding_size=2*self.encoding_size, seq_len=latent_seq_len,
                 n_layers=self.transformer_n_layers, hidden_size=self.transformer_hidden_size, n_heads=self.transformer_n_heads,
                 d_ff=self.transformer_d_ff, res_dropout=self.transformer_res_dropout, act=self.transformer_act, fc_dropout=self.transformer_fc_dropout,
                 device=self.device)
        
        return self.transformer(z, mask_included=False)








class Chomp1d(torch.nn.Module):
    """
    Removes the last elements of a time series.
    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the
    batch size, `C` is the number of input channels, and `L` is the length of
    the input. Outputs a three-dimensional tensor (`B`, `C`, `L - s`) where `s`
    is the number of elements to remove.
    @param chomp_size Number of elements to remove.
    """
    def __init__(self, chomp_size):
        super(Chomp1d, self).__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        return x[:, :, :-self.chomp_size]


class SqueezeChannels(torch.nn.Module):
    """
    Squeezes, in a three-dimensional tensor, the third dimension.
    """
    def __init__(self):
        super(SqueezeChannels, self).__init__()

    def forward(self, x):
        return x.squeeze(2)


class CausalConvolutionBlock(torch.nn.Module):
    """
    Causal convolution block, composed sequentially of two causal convolutions
    (with leaky ReLU activation functions), and a parallel residual connection.
    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the
    batch size, `C` is the number of input channels, and `L` is the length of
    the input. Outputs a three-dimensional tensor (`B`, `C`, `L`).
    @param in_channels Number of input channels.
    @param out_channels Number of output channels.
    @param kernel_size Kernel size of the applied non-residual convolutions.
    @param dilation Dilation parameter of non-residual convolutions.
    @param final Disables, if True, the last activation function.
    """
    def __init__(self, in_channels, out_channels, kernel_size, dilation,
                 final=False):
        super(CausalConvolutionBlock, self).__init__()

        # Computes left padding so that the applied convolutions are causal
        padding = (kernel_size - 1) * dilation

        # First causal convolution
        # for each output channel, it applies a different filter over each input channel then sums the results.
        conv1 = torch.nn.utils.weight_norm(torch.nn.Conv1d(
            in_channels, out_channels, kernel_size,
            padding=padding, dilation=dilation
        ))
        # The truncation makes the convolution causal
        chomp1 = Chomp1d(padding)
        relu1 = torch.nn.LeakyReLU()

        # Second causal convolution
        conv2 = torch.nn.utils.weight_norm(torch.nn.Conv1d(
            out_channels, out_channels, kernel_size,
            padding=padding, dilation=dilation
        ))
        chomp2 = Chomp1d(padding)
        relu2 = torch.nn.LeakyReLU()

        # Causal network
        self.causal = torch.nn.Sequential(
            conv1, chomp1, relu1, conv2, chomp2, relu2
        )

        # Residual connection
        self.upordownsample = torch.nn.Conv1d(
            in_channels, out_channels, 1
        ) if in_channels != out_channels else None # Isn't this just applying another 1d convolution that just isn't dilated? Is there a simpler way to up or down sample?

        # Final activation function
        self.relu = torch.nn.LeakyReLU() if final else None

    def forward(self, x):
        out_causal = self.causal(x)
        res = x if self.upordownsample is None else self.upordownsample(x)
        if self.relu is None:
            return out_causal + res
        else:
            return self.relu(out_causal + res)


class CausalCNN(torch.nn.Module):
    """
    Causal CNN, composed of a sequence of causal convolution blocks.
    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the
    batch size, `C` is the number of input channels, and `L` is the length of
    the input. Outputs a three-dimensional tensor (`B`, `C_out`, `L`).
    @param in_channels Number of input channels.
    @param channels Number of channels processed in the network and of output
           channels.
    @param depth Depth of the network.
    @param out_channels Number of output channels.
    @param kernel_size Kernel size of the applied non-residual convolutions.
    """
    def __init__(self, in_channels, channels, depth, out_channels,
                 kernel_size):
        super(CausalCNN, self).__init__()

        layers = []  # List of causal convolution blocks
        dilation_size = 1  # Initial dilation size

        for i in range(depth):
            in_channels_block = in_channels if i == 0 else channels # in the first layer the number of channels is based on the data, so in_channels. In the rest of the layers, input/output is channels.
            layers += [CausalConvolutionBlock(
                in_channels_block, channels, kernel_size, dilation_size
            )]
            dilation_size *= 2  # Doubles the dilation size at each step

        # Last layer
        layers += [CausalConvolutionBlock(
            channels, out_channels, kernel_size, dilation_size
        )]

        self.network = torch.nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)


class CausalCNNEncoder(torch.nn.Module):
    """
    Encoder of a time series using a causal CNN: the computed representation is
    the output of a fully connected layer applied to the output of an adaptive
    max pooling layer applied on top of the causal CNN, which reduces the
    length of the time series to a fixed size.
    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the
    batch size, `C` is the number of input channels, and `L` is the length of
    the input. Outputs a three-dimensional tensor (`B`, `C`).
    @param in_channels Number of input channels.
    @param channels Number of channels manipulated in the causal CNN.
    @param depth Depth of the causal CNN.
    @param reduced_size Fixed length to which the output time series of the
           causal CNN is reduced.
    @param encoding_size Number of output channels.
    @param kernel_size Kernel size of the applied non-residual convolutions.
    @param window_size windows of data to encode at a time. It should be ensured that this evenly
            divides into the length of the time series passed in. E.g. window_size is 120, and 
            x.shape[-1] (where x is passed into forward) is 120*c for some natural number c
    """
    def __init__(self, in_channels, channels, depth, reduced_size,
                 encoding_size, kernel_size, device, window_size):
        super(CausalCNNEncoder, self).__init__()
        self.encoding_size = encoding_size
        self.device = device
        causal_cnn = CausalCNN(
            in_channels, channels, depth, reduced_size, kernel_size
        )
        reduce_size = torch.nn.AdaptiveMaxPool1d(1)
        squeeze = SqueezeChannels()  # Squeezes the third dimension (time)
        linear = torch.nn.Linear(reduced_size, encoding_size)
        self.network = torch.nn.Sequential(
            causal_cnn, reduce_size, squeeze, linear
        ).to(device)

        self.window_size = window_size
        self.pruning_mask = torch.ones(self.encoding_size).bool() # This will be used to prune encoding dimensions that 
        self.pruned_encoding_size = int(torch.sum(self.pruning_mask))
        

    def forward(self, x, return_pruned=True):
        x = x.to(self.device)
        if len(tuple(x.shape)) == 4 and x.shape[1] == 2: # Meaning maps are included
            x = torch.reshape(x, (x.shape[0], x.shape[2]*2, x.shape[3]))
        
        elif len(tuple(x.shape)) == 3 and x.shape[0] == 2: # Maps are included
            x = torch.unsqueeze(x, 0) # Make it a batch of size 1, shape is (1, 2, num_features, seq_len)
            x = torch.reshape(x, (x.shape[0], x.shape[2]*2, x.shape[3]))
        
        elif len(tuple(x.shape)) == 3 and x.shape[0] != 2: # Maps aren't include. x is of shape (bs, num_featuers, seq_len)
            pass
        
        

        if return_pruned:
            return self.network(x)[:, self.pruning_mask]
        else:
            return self.network(x)

    def forward_seq(self, x, return_encoding_mask=False, sliding_gap=None, return_pruned=True):
        '''Takes a tensor of shape (num_samples, 2, num_features, seq_len) of timeseries data.
        
        Returns a tensor of shape (num_samples, seq_len/winow_size, encoding_size)'''
        assert x.shape[-1] % self.window_size == 0
        if len(tuple(x.shape)) == 3 and x.shape[1] == 2: # If a 3D tensor with maps is passed in, add a new dimension of size 1 to make it a batch of size 1
            x = torch.unsqueeze(x, 0)

        if sliding_gap:
            # This is a tensor of indices. If the data is of shape (num_samples, 2, num_features, 10), and window_size = 4 and sliding_gap=2, then inds is an array
            # of [0, 1, 2, 3, 2, 3, 4, 5, 4, 5, 6, 7, 6, 7, 8, 9]
            inds = torch.cat([torch.arange(ind, ind+self.window_size) for ind in range(0, x.shape[-1]-self.window_size+1, sliding_gap)])
            
            # Now for each sample we have the window_size windows concatenated for each sliding gap on the last axis.
            # So if window_size is 120 and sliding_gap is 20, then for each sample, the time dimension will go 
            # [0, 1, 2, ..., 119, 20, 21, ..., 139, 140, ...]
            x = torch.index_select(input=x, dim=3, index=inds)

        if return_encoding_mask:
            if x.shape[1] == 2:
                encoding_mask  = torch.sum(x[:, 1, :, :]==0, dim=1) # Of shape (num_samples, seq_len). the ij'th element is = num_features if that time step was fully imputed, <num_features otherwise
                encoding_mask[torch.where(encoding_mask < x.shape[2])] = 0 # Of shape (num_samples, seq_len). the ij'th element is = num_features if that time step was fully imputed, 0 otherwise
                encoding_mask = encoding_mask[:, self.window_size-1::self.window_size] # Of shape (num_samples, seq_len/self.window_size). On the second dim, only keeps every self.window_size'th element
                encoding_mask[encoding_mask == x.shape[2]] = -1 # Now the ij'th element is -1 if the j'th encoding from sample i was derived from fully imputed data. 0 otherwise
            else:
                encoding_mask = torch.ones(x.shape[0], x.shape[-1]//self.window_size)
        
        if len(tuple(x.shape)) == 4:
            num_samples, num_channels, num_features, seq_len = x.shape
            #print('entering forward_seq!')
            #print('num_samples, two, num_features, seq_len', num_samples, two, num_features, seq_len)
            x = torch.reshape(x, (num_samples, num_features*num_channels, seq_len)) # now x is of shape (num_samples, num_channels*num_features, seq_len)
            #print(x.shape, '==', num_samples, 2*num_features, seq_len)
            x = x.permute(1, 0, 2)
            x = x.reshape(num_channels*num_features, -1) # Now of shape (2*num_features, num_samples*seq_len)
            #print(x.shape, '==', 2*num_features, num_samples*seq_len)
            x = torch.stack(torch.split(x, self.window_size, dim=1)) # Now of shape (num_samples*(seq_len/window_size), num_channels*num_features, window_size)
            #print(x.shape, '==', num_samples*(seq_len/self.window_size), num_channels*num_features, self.window_size)

            encodings = self.forward(x, return_pruned=return_pruned) # encodings is of shape (num_samples*(seq_len/window_size), encoding_size)
            #print(encodings.shape, '==', num_samples*(seq_len/self.window_size), self.pruned_encoding_size)
            encodings = encodings.reshape(num_samples, int(seq_len/self.window_size), self.pruned_encoding_size)
        
        elif len(tuple(x.shape)) == 3:
            num_samples, num_features, seq_len = x.shape
            x = x.permute(1, 0, 2)
            x = x.reshape(num_features, -1) # Now of shape (num_features, num_samples*seq_len)
            #print(x.shape, '==', 2*num_features, num_samples*seq_len)
            x = torch.stack(torch.split(x, self.window_size, dim=1)) # Now of shape (num_samples*(seq_len/window_size), num_features, window_size)
            

            encodings = self.forward(x, return_pruned=return_pruned) # encodings is of shape (num_samples*(seq_len/window_size), encoding_size)
            #print(encodings.shape, '==', num_samples*(seq_len/self.window_size), self.pruned_encoding_size)
            encodings = encodings.reshape(num_samples, int(seq_len/self.window_size), self.pruned_encoding_size)
        
        if return_encoding_mask:
            return encodings, encoding_mask
        else:
            return encodings






